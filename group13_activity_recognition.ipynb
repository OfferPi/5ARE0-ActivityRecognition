{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93c51ad9",
   "metadata": {},
   "source": [
    "# Human Activity Recognition – Assignment 1  \n",
    "### 5ARE0, Academic Year 2025–2026  \n",
    "\n",
    "**Group 13**  \n",
    "\n",
    "**Contributors:**  \n",
    "- Stan Lamerikx\n",
    "- Simon Lammertink\n",
    "- Philip Offermans\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cedcfa",
   "metadata": {},
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81baf178",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from typing import Iterable, Dict, List, Optional, Tuple, Union\n",
    "from scipy.signal import butter, filtfilt\n",
    "from collections import Counter\n",
    "import random\n",
    "from __future__ import annotations\n",
    "from typing import Dict, List\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148e5aa5",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c73f6ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted ./data/running_2.zip to ./data/running_2\n",
      "Extracted ./data/walking_2.zip to ./data/walking_2\n",
      "Extracted ./data/sittingDown+StandingUp_2.zip to ./data/sittingDown+StandingUp_2\n",
      "Extracted ./data/climbingStairs_1.zip to ./data/climbingStairs_1\n",
      "Extracted ./data/running_1.zip to ./data/running_1\n",
      "Extracted ./data/climbingStairs_3.zip to ./data/climbingStairs_3\n",
      "Extracted ./data/climbingStairs_2.zip to ./data/climbingStairs_2\n",
      "Extracted ./data/sittingDown+StandingUp_1.zip to ./data/sittingDown+StandingUp_1\n",
      "Extracted ./data/walking_3.zip to ./data/walking_3\n",
      "Extracted ./data/sittingDown+StandingUp_3.zip to ./data/sittingDown+StandingUp_3\n",
      "Extracted ./data/running_3.zip to ./data/running_3\n",
      "Extracted ./data/walking_1.zip to ./data/walking_1\n"
     ]
    }
   ],
   "source": [
    "# Folder where your zip files are stored\n",
    "zip_folder = \"./data\"\n",
    "\n",
    "data_dirs = []\n",
    "# Loop through all files in the folder\n",
    "for file in os.listdir(zip_folder):\n",
    "    if file.endswith(\".zip\"):\n",
    "        zip_path = os.path.join(zip_folder, file)\n",
    "        extract_dir = os.path.splitext(zip_path)[0]  # remove .zip\n",
    "        \n",
    "        # Add folder to list of folders with data\n",
    "        data_dirs.append(extract_dir)\n",
    "\n",
    "        # Create the directory if it doesn't exist\n",
    "        os.makedirs(extract_dir, exist_ok=True)\n",
    "\n",
    "        # Extract contents\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(extract_dir)\n",
    "\n",
    "        print(f\"Extracted {zip_path} to {extract_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91b1de08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _csv_to_df(csv_path: Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Read CSV -> drop 'time' if present -> return as DataFrame.\n",
    "    Keeps all other columns.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    if \"time\" in df.columns:\n",
    "        df = df.drop(columns=[\"time\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486d8aab",
   "metadata": {},
   "source": [
    "## Load data as object and remove beginning and ending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9d35b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _csv_to_df(csv_path: Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Read CSV -> drop 'time' if present -> return as DataFrame.\n",
    "    Keeps all other columns. Handle missing values.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # Drop redundant 'time' column if present\n",
    "    if \"time\" in df.columns:\n",
    "        df = df.drop(columns=[\"time\"])\n",
    "\n",
    "    # Check and interpolate missing values\n",
    "    if df.isna().any().any():\n",
    "        print(\"MISSING VALUE\")\n",
    "        df = df.interpolate(method=\"linear\").dropna()\n",
    "    return df\n",
    "\n",
    "\n",
    "def _cut(df: pd.DataFrame, t_min: float, t_max: float, reset_zero: bool = True) -> pd.DataFrame:\n",
    "    \"\"\"Time-cut and (optionally) reset seconds_elapsed to start at 0.\"\"\"\n",
    "    cut = df[(df[\"seconds_elapsed\"] >= t_min) & (df[\"seconds_elapsed\"] <= t_max)].copy()\n",
    "    cut.sort_values(\"seconds_elapsed\", inplace=True, kind=\"stable\")\n",
    "    cut.reset_index(drop=True, inplace=True)\n",
    "    if not cut.empty and reset_zero:\n",
    "        cut[\"seconds_elapsed\"] = cut[\"seconds_elapsed\"] - cut[\"seconds_elapsed\"].iloc[0]\n",
    "    return cut\n",
    "\n",
    "\n",
    "SENSORS: list[str] = [\n",
    "    \"AccelerometerUncalibrated\",\n",
    "    \"Accelerometer\",\n",
    "    \"Gyroscope\",\n",
    "    \"GyroscopeUncalibrated\",\n",
    "    \"Gravity\",\n",
    "]\n",
    "\n",
    "ACTIONS: list[str] = [\n",
    "    \"climbingStairs\",\n",
    "    \"running\",\n",
    "    \"sittingDown+StandingUp\",\n",
    "    \"walking\",\n",
    "]\n",
    "\n",
    "def load_data(sensors: list[str], actions: list[str], location: str = \"./data/{action}*/\") -> dict:\n",
    "    \"\"\"\n",
    "    Explain what this function does\n",
    "    \"\"\"\n",
    "    # Create empty dict to store data\n",
    "    cut_data = {}\n",
    "\n",
    "    # Go trough all actions\n",
    "    for action in actions:\n",
    "        # find all recordings for an action\n",
    "        rec_dirs = [d for d in glob.glob(location.format(action=action))]\n",
    "        # Set the cut moments (different for the sittingDown+StandingUp action)\n",
    "        if action == \"sittingDown+StandingUp\":\n",
    "            t_min, t_max = 25.0, 565.1\n",
    "        else:\n",
    "            t_min, t_max = 25.0, 295.1\n",
    "\n",
    "        # \n",
    "        cut_data[action] = {}\n",
    "        # Go trough all recordings\n",
    "        for rec in rec_dirs:\n",
    "            # Go trough all sensors\n",
    "            for sensor in sensors:\n",
    "                # Create location of csv\n",
    "                csv_path = f\"{rec}{sensor}.csv\"\n",
    "                df = _csv_to_df(csv_path)\n",
    "                df_cut = _cut(df, t_min, t_max, reset_zero=True)\n",
    "                # Initialize list if it doesn't exist\n",
    "                if sensor not in cut_data[action]:\n",
    "                    cut_data[action][sensor] = [df_cut]\n",
    "                else:\n",
    "                    cut_data[action][sensor].append(df_cut) \n",
    "    return cut_data\n",
    "\n",
    "data_raw = load_data(sensors=SENSORS, actions=ACTIONS, location=\"./data/{action}*/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731c98d0",
   "metadata": {},
   "source": [
    "## Normalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f989979",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(data: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Normalize all recordings per sensor across participants.\n",
    "    Uses global mean/std for each axis of each sensor.\n",
    "    \"\"\"\n",
    "    # 1. Collect all values for each sensor+axis\n",
    "    stats = {}\n",
    "    for action, sensors in data.items():\n",
    "        for sensor, recordings in sensors.items():\n",
    "            if sensor not in stats:\n",
    "                stats[sensor] = {\"x\": [], \"y\": [], \"z\": []}\n",
    "            for df in recordings:\n",
    "                for axis in [\"x\", \"y\", \"z\"]:\n",
    "                    stats[sensor][axis].extend(df[axis].to_list())\n",
    "\n",
    "    # 2. Compute mean and std\n",
    "    for sensor in stats:\n",
    "        for axis in stats[sensor]:\n",
    "            arr = np.array(stats[sensor][axis])\n",
    "            stats[sensor][axis] = {\"mean\": arr.mean(), \"std\": arr.std()}\n",
    "\n",
    "    # 3. Apply normalization\n",
    "    norm_data = {}\n",
    "    for action, sensors in data.items():\n",
    "        norm_data[action] = {}\n",
    "        for sensor, recordings in sensors.items():\n",
    "            norm_data[action][sensor] = []\n",
    "            for df in recordings:\n",
    "                df_norm = df.copy()\n",
    "                for axis in [\"x\", \"y\", \"z\"]:\n",
    "                    mean = stats[sensor][axis][\"mean\"]\n",
    "                    std = stats[sensor][axis][\"std\"]\n",
    "                    if std > 0:\n",
    "                        df_norm[axis] = (df_norm[axis] - mean) / std\n",
    "                norm_data[action][sensor].append(df_norm)\n",
    "\n",
    "    return norm_data\n",
    "\n",
    "data_norm = normalize_data(data_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788cd8d0",
   "metadata": {},
   "source": [
    "## Filter / noise reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51529e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(series, window_size: int = 5):\n",
    "    return series.rolling(window=window_size, center=True, min_periods=1).mean()\n",
    "\n",
    "def low_pass_filter(series, cutoff_hz: float, fs: float, order: int = 4):\n",
    "    \"\"\"\n",
    "    cutoff_hz: cutoff frequency\n",
    "    fs: sampling rate (Hz)\n",
    "    \"\"\"\n",
    "    nyquist = 0.5 * fs\n",
    "    normal_cutoff = cutoff_hz / nyquist\n",
    "    b, a = butter(order, normal_cutoff, btype=\"low\", analog=False)\n",
    "    return filtfilt(b, a, series.to_numpy())\n",
    "\n",
    "def filter_data(data: dict, method: str = \"moving_average\", fs: float = 50.0) -> dict:\n",
    "    \"\"\"\n",
    "    Apply filtering to normalized data.\n",
    "    method: \"moving_average\" or \"low_pass\"\n",
    "    \"\"\"\n",
    "    filt_data = {}\n",
    "    for action, sensors in data.items():\n",
    "        filt_data[action] = {}\n",
    "        for sensor, recordings in sensors.items():\n",
    "            filt_data[action][sensor] = []\n",
    "            for df in recordings:\n",
    "                df_filt = df.copy()\n",
    "                for axis in [\"x\", \"y\", \"z\"]:\n",
    "                    if method == \"moving_average\":\n",
    "                        df_filt[axis] = moving_average(df[axis], window_size=5)\n",
    "                    elif method == \"low_pass\":\n",
    "                        df_filt[axis] = low_pass_filter(df[axis], cutoff_hz=5.0, fs=fs)\n",
    "                filt_data[action][sensor].append(df_filt)\n",
    "    return filt_data\n",
    "\n",
    "data = filter_data(data_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bdbfd2",
   "metadata": {},
   "source": [
    "## Visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e88a540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f91e2507380>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === Dash visualizer with smoothing =========================================\n",
    "# Expects: data[action][sensor] -> list[pd.DataFrame] with 'seconds_elapsed' + x/y/z numeric cols\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List\n",
    "from dash import Dash, dcc, html, Input, Output, State, no_update\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "# Optional: SciPy for Butterworth + Savitzky–Golay\n",
    "try:\n",
    "    from scipy.signal import butter, filtfilt, savgol_filter\n",
    "    SCIPY_OK = True\n",
    "except Exception:\n",
    "    SCIPY_OK = False\n",
    "\n",
    "# ---------- Helpers ----------\n",
    "def list_actions(data: dict) -> List[str]:\n",
    "    return sorted([a for a in data.keys() if isinstance(data[a], dict)])\n",
    "\n",
    "def list_sensors_for_action(data: dict, action: str) -> List[str]:\n",
    "    if action not in data or not isinstance(data[action], dict):\n",
    "        return []\n",
    "    sensors = []\n",
    "    for s, dfs in data[action].items():\n",
    "        valid = any(isinstance(df, pd.DataFrame) and not df.empty for df in (dfs or []))\n",
    "        if valid:\n",
    "            sensors.append(s)\n",
    "    return sorted(sensors)\n",
    "\n",
    "def list_recording_indices(data: dict, action: str, sensor: str) -> List[int]:\n",
    "    if action not in data or sensor not in data[action]:\n",
    "        return []\n",
    "    return [i for i, df in enumerate(data[action][sensor]) if isinstance(df, pd.DataFrame) and not df.empty]\n",
    "\n",
    "def available_axes(df: pd.DataFrame) -> List[str]:\n",
    "    axes = [c for c in [\"x\", \"y\", \"z\"] if c in df.columns]\n",
    "    if axes:\n",
    "        return axes\n",
    "    return [c for c in df.select_dtypes(\"number\").columns if c != \"seconds_elapsed\"]\n",
    "\n",
    "def infer_fs(df: pd.DataFrame) -> float | None:\n",
    "    if \"seconds_elapsed\" not in df.columns:\n",
    "        return None\n",
    "    t = df[\"seconds_elapsed\"].to_numpy()\n",
    "    dt = np.median(np.diff(t))\n",
    "    if not np.isfinite(dt) or dt <= 0:\n",
    "        return None\n",
    "    return 1.0 / dt\n",
    "\n",
    "def moving_average(x: np.ndarray, window: int) -> np.ndarray:\n",
    "    if window <= 1:\n",
    "        return x\n",
    "    # symmetric centered window via convolution; pad to keep length\n",
    "    pad = window // 2\n",
    "    xpad = np.pad(x, (pad, pad), mode=\"edge\")\n",
    "    kernel = np.ones(window) / window\n",
    "    y = np.convolve(xpad, kernel, mode=\"valid\")\n",
    "    return y\n",
    "\n",
    "def apply_smoothing(df: pd.DataFrame, axes: List[str], method: str, params: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Returns a new DataFrame with same columns; selected axes replaced or added with smoothed data.\n",
    "    If params.get(\"replace\") is False, smoothed series are added as '<axis>_sm'.\n",
    "    Supported methods: none, ma, sg, lp, hp\n",
    "    \"\"\"\n",
    "    out = df.copy()\n",
    "    if method == \"none\" or not axes:\n",
    "        return out\n",
    "\n",
    "    replace = bool(params.get(\"replace\", False))\n",
    "    # Downsample occurs outside; we smooth current df slice\n",
    "    if method == \"ma\":\n",
    "        window = int(params.get(\"ma_window\", 5))\n",
    "        window = max(1, window | 1)  # force odd\n",
    "        for a in axes:\n",
    "            if a in out.columns:\n",
    "                y = moving_average(out[a].to_numpy(), window)\n",
    "                out[a if replace else f\"{a}_sm\"] = y\n",
    "\n",
    "    elif method == \"sg\" and SCIPY_OK:\n",
    "        window = int(params.get(\"sg_window\", 7))\n",
    "        poly = int(params.get(\"sg_poly\", 3))\n",
    "        window = max(poly + 2 | 1, window | 1)  # ensure odd & >= poly+2\n",
    "        for a in axes:\n",
    "            if a in out.columns and len(out[a]) >= window:\n",
    "                y = savgol_filter(out[a].to_numpy(), window_length=window, polyorder=poly, mode=\"interp\")\n",
    "                out[a if replace else f\"{a}_sm\"] = y\n",
    "\n",
    "    elif method in (\"lp\", \"hp\") and SCIPY_OK:\n",
    "        fs = infer_fs(out)\n",
    "        if not fs:\n",
    "            return out\n",
    "        cutoff = float(params.get(\"bw_cutoff\", min(fs * 0.45, fs/2 - 1e-3)))\n",
    "        order = int(params.get(\"bw_order\", 4))\n",
    "        nyq = 0.5 * fs\n",
    "        wc = np.clip(cutoff / nyq, 1e-6, 0.999999)\n",
    "        btype = \"low\" if method == \"lp\" else \"high\"\n",
    "        b, a = butter(order, wc, btype=btype)\n",
    "        for a_col in axes:\n",
    "            if a_col in out.columns and len(out[a_col]) > order * 3:\n",
    "                y = filtfilt(b, a, out[a_col].to_numpy(), method=\"gust\")\n",
    "                out[a_col if replace else f\"{a_col}_sm\"] = y\n",
    "    # If SciPy missing for sg/lp/hp, we silently leave data unchanged (raw or MA still works)\n",
    "    return out\n",
    "\n",
    "# ---------- App ----------\n",
    "app = Dash(__name__)\n",
    "app.title = \"Recording Visualizer\"\n",
    "\n",
    "_actions = list_actions(data)\n",
    "_sensors = list_sensors_for_action(data, _actions[0]) if _actions else []\n",
    "_recs    = list_recording_indices(data, _actions[0], _sensors[0]) if (_actions and _sensors) else []\n",
    "_rec_val = _recs[0] if _recs else None\n",
    "\n",
    "app.layout = html.Div(\n",
    "    style={\"maxWidth\": \"1180px\", \"margin\": \"0 auto\", \"fontFamily\": \"Inter, system-ui, sans-serif\"},\n",
    "    children=[\n",
    "        html.H2(\"Recordings viewer\", style={\"marginTop\": \"16px\"}),\n",
    "\n",
    "        # Row 1: dataset selectors\n",
    "        html.Div(\n",
    "            style={\"display\": \"grid\", \"gridTemplateColumns\": \"1fr 1fr 1fr\", \"gap\": \"12px\"},\n",
    "            children=[\n",
    "                html.Div([\n",
    "                    html.Label(\"Action\"),\n",
    "                    dcc.Dropdown(\n",
    "                        id=\"dd-action\",\n",
    "                        options=[{\"label\": a, \"value\": a} for a in _actions],\n",
    "                        value=_actions[0] if _actions else None,\n",
    "                        clearable=False,\n",
    "                    )\n",
    "                ]),\n",
    "                html.Div([\n",
    "                    html.Label(\"Sensor\"),\n",
    "                    dcc.Dropdown(\n",
    "                        id=\"dd-sensor\",\n",
    "                        options=[{\"label\": s, \"value\": s} for s in _sensors],\n",
    "                        value=_sensors[0] if _sensors else None,\n",
    "                        clearable=False,\n",
    "                    )\n",
    "                ]),\n",
    "                html.Div([\n",
    "                    html.Label(\"Recording index\"),\n",
    "                    dcc.Dropdown(\n",
    "                        id=\"dd-rec\",\n",
    "                        options=[{\"label\": str(i), \"value\": i} for i in _recs],\n",
    "                        value=_rec_val,\n",
    "                        clearable=False,\n",
    "                    )\n",
    "                ]),\n",
    "            ],\n",
    "        ),\n",
    "\n",
    "        # Row 2: plot options\n",
    "        html.Div(\n",
    "            style={\"display\": \"grid\", \"gridTemplateColumns\": \"1fr 1fr 1fr\", \"gap\": \"12px\", \"marginTop\": \"12px\"},\n",
    "            children=[\n",
    "                html.Div([\n",
    "                    html.Label(\"Axes to plot\"),\n",
    "                    dcc.Checklist(\n",
    "                        id=\"cl-axes\",\n",
    "                        options=[],  # filled dynamically\n",
    "                        value=[],\n",
    "                        inputStyle={\"marginRight\": \"6px\", \"marginLeft\": \"12px\"},\n",
    "                        inline=True,\n",
    "                    ),\n",
    "                ]),\n",
    "                html.Div([\n",
    "                    html.Label(\"Downsample (every Nth point)\"),\n",
    "                    dcc.Slider(\n",
    "                        id=\"sl-downsample\",\n",
    "                        min=1, max=20, step=1, value=1,\n",
    "                        marks={1: \"1x\", 5: \"5x\", 10: \"10x\", 20: \"20x\"},\n",
    "                        tooltip={\"placement\":\"bottom\"}\n",
    "                    ),\n",
    "                ]),\n",
    "                html.Div([\n",
    "                    html.Label(\"Show mode\"),\n",
    "                    dcc.RadioItems(\n",
    "                        id=\"ri-showmode\",\n",
    "                        options=[\n",
    "                            {\"label\": \"Raw only\", \"value\": \"raw\"},\n",
    "                            {\"label\": \"Smoothed only\", \"value\": \"sm\"},\n",
    "                            {\"label\": \"Overlay\", \"value\": \"overlay\"},\n",
    "                        ],\n",
    "                        value=\"raw\",\n",
    "                        inline=True,\n",
    "                    ),\n",
    "                ]),\n",
    "            ]\n",
    "        ),\n",
    "\n",
    "        # Row 3: smoothing controls\n",
    "        html.Div(\n",
    "            style={\"display\": \"grid\", \"gridTemplateColumns\": \"1.2fr 1fr 1fr 1fr 1fr\", \"gap\": \"12px\", \"marginTop\": \"12px\"},\n",
    "            children=[\n",
    "                html.Div([\n",
    "                    html.Label(\"Smoothing method\"),\n",
    "                    dcc.Dropdown(\n",
    "                        id=\"dd-smooth\",\n",
    "                        options=[\n",
    "                            {\"label\": \"None\", \"value\": \"none\"},\n",
    "                            {\"label\": \"Moving Average\", \"value\": \"ma\"},\n",
    "                            {\"label\": \"Savitzky–Golay\", \"value\": \"sg\"},\n",
    "                            {\"label\": \"Butterworth Low-pass\", \"value\": \"lp\"},\n",
    "                            {\"label\": \"Butterworth High-pass\", \"value\": \"hp\"},\n",
    "                        ],\n",
    "                        value=\"none\",\n",
    "                        clearable=False,\n",
    "                    )\n",
    "                ]),\n",
    "                html.Div([\n",
    "                    html.Label(\"MA / SG window\"),\n",
    "                    dcc.Input(id=\"in-ma-sg-window\", type=\"number\", value=7, min=1, step=2, style={\"width\":\"100%\"}),\n",
    "                ]),\n",
    "                html.Div([\n",
    "                    html.Label(\"SG polyorder\"),\n",
    "                    dcc.Input(id=\"in-sg-poly\", type=\"number\", value=3, min=1, step=1, style={\"width\":\"100%\"}),\n",
    "                ]),\n",
    "                html.Div([\n",
    "                    html.Label(\"BW cutoff (Hz)\"),\n",
    "                    dcc.Input(id=\"in-bw-cutoff\", type=\"number\", value=2.0, min=0.01, step=0.1, style={\"width\":\"100%\"}),\n",
    "                ]),\n",
    "                html.Div([\n",
    "                    html.Label(\"BW order\"),\n",
    "                    dcc.Input(id=\"in-bw-order\", type=\"number\", value=4, min=1, step=1, style={\"width\":\"100%\"}),\n",
    "                ]),\n",
    "            ]\n",
    "        ),\n",
    "\n",
    "        html.Div(\n",
    "            style={\"marginTop\": \"6px\", \"fontSize\": \"12px\", \"opacity\": 0.75},\n",
    "            children=(\"Tip: Window must be odd. For SG, window ≥ polyorder+2. \"\n",
    "                      \"For Butterworth, cutoff must be < Nyquist (fs/2).\")\n",
    "        ),\n",
    "\n",
    "        dcc.Graph(id=\"graph\", figure=go.Figure(), style={\"height\": \"70vh\", \"marginTop\": \"8px\"}),\n",
    "\n",
    "        # Stores for preserving UI state\n",
    "        dcc.Store(id=\"xrange-store\"),\n",
    "        dcc.Store(id=\"current-df-meta\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# ---------- Callbacks ----------\n",
    "@app.callback(\n",
    "    Output(\"dd-sensor\", \"options\"),\n",
    "    Output(\"dd-sensor\", \"value\"),\n",
    "    Input(\"dd-action\", \"value\"),\n",
    ")\n",
    "def on_action_change(action):\n",
    "    if not action:\n",
    "        return [], None\n",
    "    sensors = list_sensors_for_action(data, action)\n",
    "    opts = [{\"label\": s, \"value\": s} for s in sensors]\n",
    "    val = sensors[0] if sensors else None\n",
    "    return opts, val\n",
    "\n",
    "@app.callback(\n",
    "    Output(\"dd-rec\", \"options\"),\n",
    "    Output(\"dd-rec\", \"value\"),\n",
    "    Input(\"dd-action\", \"value\"),\n",
    "    Input(\"dd-sensor\", \"value\"),\n",
    ")\n",
    "def on_sensor_change(action, sensor):\n",
    "    if not action or not sensor:\n",
    "        return [], None\n",
    "    recs = list_recording_indices(data, action, sensor)\n",
    "    opts = [{\"label\": str(i), \"value\": i} for i in recs]\n",
    "    val = recs[0] if recs else None\n",
    "    return opts, val\n",
    "\n",
    "@app.callback(\n",
    "    Output(\"cl-axes\", \"options\"),\n",
    "    Output(\"cl-axes\", \"value\"),\n",
    "    Output(\"current-df-meta\", \"data\"),\n",
    "    Input(\"dd-action\", \"value\"),\n",
    "    Input(\"dd-sensor\", \"value\"),\n",
    "    Input(\"dd-rec\", \"value\"),\n",
    ")\n",
    "def update_axes(action, sensor, idx):\n",
    "    if not action or not sensor or idx is None:\n",
    "        return [], [], None\n",
    "    try:\n",
    "        df = data[action][sensor][idx]\n",
    "        if df is None or df.empty:\n",
    "            return [], [], None\n",
    "        axes = available_axes(df)\n",
    "        opts = [{\"label\": a.upper(), \"value\": a} for a in axes]\n",
    "        return opts, axes, {\"action\": action, \"sensor\": sensor, \"idx\": idx}\n",
    "    except Exception:\n",
    "        return [], [], None\n",
    "\n",
    "# Remember zoom/pan; keep when changing controls\n",
    "@app.callback(\n",
    "    Output(\"xrange-store\", \"data\"),\n",
    "    Input(\"graph\", \"relayoutData\"),\n",
    "    State(\"xrange-store\", \"data\"),\n",
    "    prevent_initial_call=True,\n",
    ")\n",
    "def remember_zoom(relayout, stored):\n",
    "    if not relayout:\n",
    "        return no_update\n",
    "    if relayout.get(\"xaxis.autorange\"):\n",
    "        return None\n",
    "    x0 = relayout.get(\"xaxis.range[0]\") or (relayout.get(\"xaxis.range\", [None, None])[0] if \"xaxis.range\" in relayout else None)\n",
    "    x1 = relayout.get(\"xaxis.range[1]\") or (relayout.get(\"xaxis.range\", [None, None])[1] if \"xaxis.range\" in relayout else None)\n",
    "    if x0 is None or x1 is None:\n",
    "        return no_update\n",
    "    try:\n",
    "        return {\"x0\": float(x0), \"x1\": float(x1)}\n",
    "    except Exception:\n",
    "        return no_update\n",
    "\n",
    "@app.callback(\n",
    "    Output(\"graph\", \"figure\"),\n",
    "    Input(\"current-df-meta\", \"data\"),\n",
    "    Input(\"cl-axes\", \"value\"),\n",
    "    Input(\"sl-downsample\", \"value\"),\n",
    "    Input(\"ri-showmode\", \"value\"),\n",
    "    Input(\"dd-smooth\", \"value\"),\n",
    "    Input(\"in-ma-sg-window\", \"value\"),\n",
    "    Input(\"in-sg-poly\", \"value\"),\n",
    "    Input(\"in-bw-cutoff\", \"value\"),\n",
    "    Input(\"in-bw-order\", \"value\"),\n",
    "    State(\"xrange-store\", \"data\"),\n",
    ")\n",
    "def update_graph(meta, axes_selected, ds, showmode,\n",
    "                 sm_method, ma_sg_window, sg_poly, bw_cutoff, bw_order,\n",
    "                 xr):\n",
    "    if not meta:\n",
    "        return go.Figure()\n",
    "\n",
    "    action = meta[\"action\"]; sensor = meta[\"sensor\"]; idx = meta[\"idx\"]\n",
    "    df = data[action][sensor][idx]\n",
    "    if df is None or df.empty or \"seconds_elapsed\" not in df.columns:\n",
    "        return go.Figure()\n",
    "\n",
    "    df = df.sort_values(\"seconds_elapsed\", kind=\"stable\").dropna()\n",
    "\n",
    "    # Downsample first (so smoothing runs on what you plot)\n",
    "    if isinstance(ds, int) and ds > 1:\n",
    "        df = df.iloc[::ds, :]\n",
    "\n",
    "    axes_all = available_axes(df)\n",
    "    if not axes_selected:\n",
    "        axes_selected = axes_all\n",
    "\n",
    "    # Build smoothing params\n",
    "    params = {\n",
    "        \"replace\": (showmode == \"sm\"),\n",
    "        \"ma_window\": int(ma_sg_window or 5),\n",
    "        \"sg_window\": int(ma_sg_window or 7),\n",
    "        \"sg_poly\": int(sg_poly or 3),\n",
    "        \"bw_cutoff\": float(bw_cutoff or 2.0),\n",
    "        \"bw_order\": int(bw_order or 4),\n",
    "    }\n",
    "\n",
    "    # Apply smoothing (adds *_sm columns if not replacing)\n",
    "    df_sm = apply_smoothing(df, axes_selected, sm_method or \"none\", params)\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Decide which traces to draw\n",
    "    draw_raw = showmode in (\"raw\", \"overlay\")\n",
    "    draw_sm  = (showmode in (\"sm\", \"overlay\")) and (sm_method != \"none\")\n",
    "\n",
    "    for a in axes_selected:\n",
    "        if draw_raw and a in df_sm.columns:\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=df_sm[\"seconds_elapsed\"], y=df_sm[a],\n",
    "                mode=\"lines\", name=a.upper()+\" (raw)\",\n",
    "                line=dict(dash=\"dot\"),\n",
    "                hovertemplate=\"t=%{x:.3f}s<br>%{y:.5f}<extra>\"+a.upper()+\" raw</extra>\"\n",
    "            ))\n",
    "        if draw_sm:\n",
    "            sm_col = a if params[\"replace\"] else f\"{a}_sm\"\n",
    "            if sm_col in df_sm.columns:\n",
    "                fig.add_trace(go.Scatter(\n",
    "                    x=df_sm[\"seconds_elapsed\"], y=df_sm[sm_col],\n",
    "                    mode=\"lines\", name=a.upper()+\" (smoothed)\",\n",
    "                    hovertemplate=\"t=%{x:.3f}s<br>%{y:.5f}<extra>\"+a.upper()+\" sm</extra>\"\n",
    "                ))\n",
    "\n",
    "    # If smoothing is 'none' but user chose \"Smoothed only\", fall back to raw\n",
    "    if sm_method == \"none\" and showmode == \"sm\":\n",
    "        for a in axes_selected:\n",
    "            if a in df_sm.columns:\n",
    "                fig.add_trace(go.Scatter(\n",
    "                    x=df_sm[\"seconds_elapsed\"], y=df_sm[a],\n",
    "                    mode=\"lines\", name=a.upper(),\n",
    "                ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        xaxis_title=\"Time (s)\",\n",
    "        yaxis_title=\"Value\",\n",
    "        legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"left\", x=0),\n",
    "        margin=dict(l=40, r=20, t=30, b=40),\n",
    "        uirevision=\"keep-zoom\",  # preserve zoom/pan across updates\n",
    "    )\n",
    "    fig.update_xaxes(rangeslider=dict(visible=True))\n",
    "\n",
    "    # Re-apply stored range if present\n",
    "    if xr and all(k in xr for k in (\"x0\", \"x1\")):\n",
    "        fig.update_xaxes(range=[xr[\"x0\"], xr[\"x1\"]])\n",
    "\n",
    "    return fig\n",
    "\n",
    "# ---------- Launch (works in Jupyter) ----------\n",
    "PORT = 8050\n",
    "app.run(host=\"127.0.0.1\", port=PORT, debug=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0958130",
   "metadata": {},
   "source": [
    "## Create Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24f466d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _split_into_samples(data: pd.DataFrame, window_s: float = 5.0, reset_zero: bool = True) -> List[pd.DataFrame]:\n",
    "    t_end = float(data[\"seconds_elapsed\"].iloc[-1])\n",
    "\n",
    "    out: List[pd.DataFrame] = []\n",
    "    start = 0.0\n",
    "    while start + window_s <= t_end + 1e-9:\n",
    "        end = start + window_s\n",
    "        mask = (data[\"seconds_elapsed\"] >= start) & (data[\"seconds_elapsed\"] < end)\n",
    "        chunk = data.loc[mask].copy()\n",
    "        if not chunk.empty:\n",
    "            if reset_zero:\n",
    "                chunk[\"seconds_elapsed\"] = chunk[\"seconds_elapsed\"] - chunk[\"seconds_elapsed\"].iloc[0]\n",
    "            out.append(chunk.reset_index(drop=True))\n",
    "        start = end\n",
    "    return out\n",
    "\n",
    "\n",
    "def build_samples(data: Dict[str, Dict[str, List[pd.DataFrame]]]) -> Dict[str, Dict[str, List[pd.DataFrame]]]:\n",
    "    \"\"\"\n",
    "    Convert cut_data into samples:\n",
    "        samples[action][sensor] -> list of 5s DataFrames\n",
    "    \"\"\"\n",
    "    samples: Dict[str, Dict[str, List[pd.DataFrame]]] = {}\n",
    "    for action, sensors in data.items():\n",
    "        if action != 'sittingDown+StandingUp':\n",
    "            samples[action] = {}\n",
    "        else:\n",
    "            samples['sittingDown'] = {}\n",
    "            samples['standingUp'] = {}\n",
    "        for sensor, recordings in sensors.items():\n",
    "            if action != 'sittingDown+StandingUp':\n",
    "                sensor_samples: List[pd.DataFrame] = []\n",
    "                for rec_df in recordings:\n",
    "                    split_samples = _split_into_samples(rec_df)\n",
    "                    sensor_samples.extend(split_samples)\n",
    "                samples[action][sensor] = sensor_samples\n",
    "            else:\n",
    "                sitting_down_samples: List[pd.DataFrame] = []\n",
    "                standing_up_samples: List[pd.DataFrame] = []\n",
    "                for rec_df in recordings:\n",
    "                    split_samples = _split_into_samples(rec_df)\n",
    "                    sitting_down_samples.extend(split_samples[0::2])\n",
    "                    standing_up_samples.extend(split_samples[1::2])\n",
    "                samples['sittingDown'][sensor] = sitting_down_samples\n",
    "                samples['standingUp'][sensor] = standing_up_samples\n",
    "    return samples\n",
    "\n",
    "samples = build_samples(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab0d412",
   "metadata": {},
   "source": [
    "## Find good sample window based on samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93176654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% at or below period ≈ 2.50 s\n",
      "Suggested window ≈ 5.00 s (≈ 2 cycles)\n"
     ]
    }
   ],
   "source": [
    "def fft(df, signal_col, time_col=\"seconds_elapsed\"):\n",
    "    # Extract time and signal\n",
    "    t = df[time_col].to_numpy()\n",
    "    sig = df[signal_col].to_numpy()\n",
    "\n",
    "    # Sampling frequency (Hz)\n",
    "    dt = np.median(np.diff(t))   # average timestep\n",
    "    fs = 1.0 / dt                # sampling rate\n",
    "\n",
    "    # Remove DC offset\n",
    "    sig = sig - np.mean(sig)\n",
    "\n",
    "    # FFT\n",
    "    n = len(sig)\n",
    "    f = np.fft.rfftfreq(n, d=1/fs)   # frequency bins\n",
    "    Y = np.fft.rfft(sig)             # real FFT\n",
    "    mag = np.abs(Y) / n              # normalize magnitude\n",
    "\n",
    "    return f, mag\n",
    "\n",
    "def periods(freqs, mag, t_max=8, step=0.1):\n",
    "    mask = freqs > 0\n",
    "    freqs = freqs[mask]\n",
    "    mag = mag[mask]\n",
    "\n",
    "    periods = 1.0 / freqs\n",
    "    bins = np.arange(0, t_max + step, step)\n",
    "\n",
    "    # USE POWER WEIGHTS (energy), not ones\n",
    "    power = (mag ** 2)\n",
    "\n",
    "    counts, edges = np.histogram(periods, bins=bins, weights=power)\n",
    "\n",
    "    result = pd.DataFrame({\n",
    "        \"period_s\": edges[:-1],\n",
    "        \"power\": counts  # rename to reflect energy\n",
    "    })\n",
    "    return result\n",
    "\n",
    "combined_hist = None\n",
    "for action in samples.keys():\n",
    "    for sensor in samples[action].keys():\n",
    "        for sample in samples[action][sensor]:\n",
    "            for axis in ['x','y','z']:\n",
    "                f, mag = fft(sample, axis)\n",
    "                hist = periods(f, mag)\n",
    "                if combined_hist is None:\n",
    "                    combined_hist = hist.copy()\n",
    "                else:\n",
    "                    combined_hist[\"power\"] += hist[\"power\"].to_numpy()\n",
    "\n",
    "total = combined_hist[\"power\"].sum()\n",
    "combined_hist[\"cum_power\"] = combined_hist[\"power\"].cumsum()\n",
    "combined_hist[\"cum_frac\"]  = combined_hist[\"cum_power\"] / total\n",
    "\n",
    "target = 0.95\n",
    "cut_period = combined_hist.loc[combined_hist[\"cum_frac\"] >= target, \"period_s\"].iloc[0]\n",
    "print(f\"{int(target*100)}% at or below period ≈ {cut_period:.2f} s\")\n",
    "\n",
    "cycles = 2\n",
    "window_seconds = cycles * cut_period\n",
    "print(f\"Suggested window ≈ {window_seconds:.2f} s (≈ {cycles} cycles)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae66e75",
   "metadata": {},
   "source": [
    "## Find good sample window based on full data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38ffebbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% at or below period ≈ 2.20 s\n",
      "Suggested window ≈ 4.40 s (≈ 2 cycles)\n"
     ]
    }
   ],
   "source": [
    "combined_hist = None\n",
    "for action in data.keys():\n",
    "    for sensor in data[action].keys():\n",
    "        for sample in data[action][sensor]:\n",
    "                for axis in ['x','y','z']:\n",
    "                    f, mag = fft(sample, axis)\n",
    "                    hist = periods(f, mag)\n",
    "                    if combined_hist is None:\n",
    "                        combined_hist = hist.copy()\n",
    "                    else:\n",
    "                        combined_hist[\"power\"] += hist[\"power\"].to_numpy()\n",
    "\n",
    "total = combined_hist[\"power\"].sum()\n",
    "combined_hist[\"cum_power\"] = combined_hist[\"power\"].cumsum()\n",
    "combined_hist[\"cum_frac\"]  = combined_hist[\"cum_power\"] / total\n",
    "\n",
    "target = 0.95\n",
    "cut_period = combined_hist.loc[combined_hist[\"cum_frac\"] >= target, \"period_s\"].iloc[0]\n",
    "print(f\"{int(target*100)}% at or below period ≈ {cut_period:.2f} s\")\n",
    "\n",
    "cycles = 2\n",
    "window_seconds = cycles * cut_period\n",
    "print(f\"Suggested window ≈ {window_seconds:.2f} s (≈ {cycles} cycles)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3de40c0",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c3de97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_samples(\n",
    "    samples: Dict[str, Dict[str, List[pd.DataFrame]]],\n",
    "    train_ratio: float = 0.70,\n",
    "    val_ratio: float = 0.15,\n",
    "    test_ratio: float = 0.15,\n",
    "    seed: int = 42,\n",
    "    shuffle: bool = True,\n",
    ") -> Tuple[Dict[str, Dict[str, List[pd.DataFrame]]],\n",
    "           Dict[str, Dict[str, List[pd.DataFrame]]],\n",
    "           Dict[str, Dict[str, List[pd.DataFrame]]]]:\n",
    "    \n",
    "    def _init_empty_object(src):\n",
    "        out: Dict[str, Dict[str, List[pd.DataFrame]]] = {}\n",
    "        for action, sensors in src.items():\n",
    "            out[action] = {}\n",
    "            for sensor in sensors.keys():\n",
    "                out[action][sensor] = []\n",
    "        return out\n",
    "    \n",
    "    train = _init_empty_object(samples)\n",
    "    val   = _init_empty_object(samples)\n",
    "    test  = _init_empty_object(samples)\n",
    "    \n",
    "    random_number = random.Random(seed)\n",
    "\n",
    "    for action in samples.keys():\n",
    "        for sensor in samples[action].keys():\n",
    "            sample_list = samples[action][sensor] \n",
    "            n = len(sample_list)\n",
    "\n",
    "            sample_nums = list(range(n))\n",
    "            if shuffle:\n",
    "                random_number.shuffle(sample_nums)\n",
    "\n",
    "            # Compute split sizes (ensure they sum to n)\n",
    "            n_train = int(n * train_ratio)\n",
    "            n_val   = int(n * val_ratio)\n",
    "\n",
    "            sample_nums_train = sample_nums[:n_train]\n",
    "            sample_nums_val   = sample_nums[n_train:n_train + n_val]\n",
    "            sample_nums_test  = sample_nums[n_train + n_val:]\n",
    "\n",
    "\n",
    "            train[action][sensor] = [sample_list[i] for i in sample_nums_train]\n",
    "            val[action][sensor]   = [sample_list[i] for i in sample_nums_val]\n",
    "            test[action][sensor]  = [sample_list[i] for i in sample_nums_test]\n",
    "\n",
    "    return train, val, test\n",
    "\n",
    "train_samples, val_samples, test_samples = split_samples(samples, 0.70, 0.15, 0.15, seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea25eb9",
   "metadata": {},
   "source": [
    "## Visualize Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f982720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f91e52d2350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# app_samples_viewer.py\n",
    "import os\n",
    "from typing import Dict, List\n",
    "import pandas as pd\n",
    "from dash import Dash, dcc, html, Input, Output, State, ctx, no_update\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "# ---------- IMPORTANT ----------\n",
    "# Expect these to be available in the global scope if you've split already:\n",
    "#   train_samples, val_samples, test_samples\n",
    "# If not present, the app will fall back to `samples`.\n",
    "try:\n",
    "    samples  # type: ignore # noqa: F821\n",
    "except NameError:\n",
    "    # Dummy fallback to avoid NameError if you run this file standalone.\n",
    "    # Replace this with your real data before running.\n",
    "    samples = {\"walking\": {\"Accelerometer\": []}}\n",
    "\n",
    "# Helper: return the dict for a chosen dataset name\n",
    "def get_dataset_dict(dataset_name: str) -> Dict[str, Dict[str, List[pd.DataFrame]]]:\n",
    "    # Prefer explicitly split sets if available; otherwise fallback to `samples`\n",
    "    if dataset_name == \"train\" and \"train_samples\" in globals():\n",
    "        return globals()[\"train_samples\"]\n",
    "    if dataset_name == \"val\" and \"val_samples\" in globals():\n",
    "        return globals()[\"val_samples\"]\n",
    "    if dataset_name == \"test\" and \"test_samples\" in globals():\n",
    "        return globals()[\"test_samples\"]\n",
    "    # Fallback (treat whole thing as \"all\")\n",
    "    return samples\n",
    "\n",
    "def get_actions(dataset_name: str) -> List[str]:\n",
    "    ds = get_dataset_dict(dataset_name)\n",
    "    return list(ds.keys())\n",
    "\n",
    "def get_sensors(dataset_name: str, action: str) -> List[str]:\n",
    "    ds = get_dataset_dict(dataset_name)\n",
    "    return list(ds.get(action, {}).keys())\n",
    "\n",
    "def get_sample_count(dataset_name: str, action: str, sensor: str) -> int:\n",
    "    ds = get_dataset_dict(dataset_name)\n",
    "    return len(ds.get(action, {}).get(sensor, []))\n",
    "\n",
    "def make_sample_options(dataset_name: str, action: str, sensor: str, max_options: int = 10000):\n",
    "    n = get_sample_count(dataset_name, action, sensor)\n",
    "    return [{\"label\": f\"Sample {i}\", \"value\": i} for i in range(min(n, max_options))]\n",
    "\n",
    "app = Dash(__name__)\n",
    "server = app.server\n",
    "\n",
    "app.layout = html.Div([\n",
    "    html.H2(\"Sample Browser\"),\n",
    "    html.Div([\n",
    "        html.Div([\n",
    "            html.Label(\"Dataset\"),\n",
    "            dcc.Dropdown(\n",
    "                id=\"ddl-dataset\",\n",
    "                options=[\n",
    "                    {\"label\": \"Train\", \"value\": \"train\"},\n",
    "                    {\"label\": \"Validation\", \"value\": \"val\"},\n",
    "                    {\"label\": \"Test\", \"value\": \"test\"},\n",
    "                    {\"label\": \"All (fallback to samples)\", \"value\": \"all\"},\n",
    "                ],\n",
    "                value=\"train\" if \"train_samples\" in globals() else (\"all\"),\n",
    "                clearable=False,\n",
    "            ),\n",
    "        ], style={\"width\": \"18%\"}),\n",
    "\n",
    "        html.Div([\n",
    "            html.Label(\"Action\"),\n",
    "            dcc.Dropdown(\n",
    "                id=\"ddl-action\",\n",
    "                options=[],\n",
    "                value=None,\n",
    "                clearable=False,\n",
    "            ),\n",
    "        ], style={\"width\": \"22%\"}),\n",
    "\n",
    "        html.Div([\n",
    "            html.Label(\"Sensor\"),\n",
    "            dcc.Dropdown(\n",
    "                id=\"ddl-sensor\",\n",
    "                options=[],\n",
    "                value=None,\n",
    "                clearable=False,\n",
    "            ),\n",
    "        ], style={\"width\": \"22%\"}),\n",
    "\n",
    "        html.Div([\n",
    "            html.Label(\"Samples\"),\n",
    "            dcc.Dropdown(\n",
    "                id=\"ddl-samples\",\n",
    "                options=[],\n",
    "                value=[],\n",
    "                multi=True,\n",
    "                placeholder=\"Select one or more samples\",\n",
    "            ),\n",
    "        ], style={\"width\": \"28%\"}),\n",
    "\n",
    "        html.Div([\n",
    "            html.Label(\"View Mode\"),\n",
    "            dcc.RadioItems(\n",
    "                id=\"rad-mode\",\n",
    "                options=[\n",
    "                    {\"label\": \"Overlay\", \"value\": \"overlay\"},\n",
    "                    {\"label\": \"Separate\", \"value\": \"separate\"},\n",
    "                ],\n",
    "                value=\"overlay\",\n",
    "                inline=True,\n",
    "            ),\n",
    "        ], style={\"width\": \"10%\"}),\n",
    "    ], style={\"display\": \"flex\", \"gap\": \"1rem\", \"flexWrap\": \"wrap\", \"alignItems\": \"end\"}),\n",
    "\n",
    "    html.Div([\n",
    "        dcc.Checklist(\n",
    "            id=\"chk-axes\",\n",
    "            options=[{\"label\": \"x\", \"value\": \"x\"},\n",
    "                     {\"label\": \"y\", \"value\": \"y\"},\n",
    "                     {\"label\": \"z\", \"value\": \"z\"}],\n",
    "            value=[\"x\", \"y\", \"z\"],\n",
    "            inline=True\n",
    "        ),\n",
    "        html.Span(\"  (toggle axes)\", style={\"marginLeft\": \"0.5rem\", \"color\": \"#666\"})\n",
    "    ], style={\"margin\": \"0.5rem 0 1rem 0\"}),\n",
    "\n",
    "    dcc.Loading(\n",
    "        dcc.Graph(id=\"graph\", figure=go.Figure()),\n",
    "        type=\"default\"\n",
    "    ),\n",
    "], style={\"maxWidth\": \"1200px\", \"margin\": \"1.5rem auto\", \"fontFamily\": \"sans-serif\"})\n",
    "\n",
    "# --- Callbacks ---\n",
    "\n",
    "# Populate actions based on dataset, and persist selection if valid\n",
    "@app.callback(\n",
    "    Output(\"ddl-action\", \"options\"),\n",
    "    Output(\"ddl-action\", \"value\"),\n",
    "    Input(\"ddl-dataset\", \"value\"),\n",
    "    State(\"ddl-action\", \"value\"),\n",
    ")\n",
    "def on_dataset_change(dataset_name, current_action):\n",
    "    actions = get_actions(dataset_name or \"all\")\n",
    "    opts = [{\"label\": a, \"value\": a} for a in actions]\n",
    "    if not actions:\n",
    "        return [], None\n",
    "    value = current_action if current_action in actions else actions[0]\n",
    "    return opts, value\n",
    "\n",
    "# Keep sensor selection when action or dataset changes (if still valid)\n",
    "@app.callback(\n",
    "    Output(\"ddl-sensor\", \"options\"),\n",
    "    Output(\"ddl-sensor\", \"value\"),\n",
    "    Input(\"ddl-dataset\", \"value\"),\n",
    "    Input(\"ddl-action\", \"value\"),\n",
    "    State(\"ddl-sensor\", \"value\"),\n",
    ")\n",
    "def on_action_change(dataset_name, action, current_sensor):\n",
    "    if not dataset_name or not action:\n",
    "        return [], None\n",
    "    sensors = get_sensors(dataset_name, action)\n",
    "    opts = [{\"label\": s, \"value\": s} for s in sensors]\n",
    "    if not sensors:\n",
    "        return [], None\n",
    "    value = current_sensor if current_sensor in sensors else sensors[0]\n",
    "    return opts, value\n",
    "\n",
    "# Keep sample selection when sensor/action/dataset changes (if still valid)\n",
    "@app.callback(\n",
    "    Output(\"ddl-samples\", \"options\"),\n",
    "    Output(\"ddl-samples\", \"value\"),\n",
    "    Input(\"ddl-dataset\", \"value\"),\n",
    "    Input(\"ddl-action\", \"value\"),\n",
    "    Input(\"ddl-sensor\", \"value\"),\n",
    "    State(\"ddl-samples\", \"value\"),\n",
    ")\n",
    "def on_sensor_change(dataset_name, action, sensor, current_samples):\n",
    "    if not dataset_name or not action or not sensor:\n",
    "        return [], []\n",
    "    opts = make_sample_options(dataset_name, action, sensor)\n",
    "    valid = {o[\"value\"] for o in opts}\n",
    "    kept = [v for v in (current_samples or []) if v in valid]\n",
    "    # auto-pick first if nothing selected\n",
    "    if not kept and opts:\n",
    "        kept = [opts[0][\"value\"]]\n",
    "    return opts, kept\n",
    "\n",
    "@app.callback(\n",
    "    Output(\"graph\", \"figure\"),\n",
    "    Input(\"ddl-dataset\", \"value\"),\n",
    "    Input(\"ddl-action\", \"value\"),\n",
    "    Input(\"ddl-sensor\", \"value\"),\n",
    "    Input(\"ddl-samples\", \"value\"),\n",
    "    Input(\"rad-mode\", \"value\"),\n",
    "    Input(\"chk-axes\", \"value\"),\n",
    ")\n",
    "def update_plot(dataset_name, action, sensor, selected_samples, mode, axes_on):\n",
    "    fig = go.Figure()\n",
    "\n",
    "    if not dataset_name or not action or not sensor or not selected_samples:\n",
    "        fig.update_layout(\n",
    "            title=\"Select dataset, action, sensor, and samples\",\n",
    "            xaxis_title=\"Time (s)\",\n",
    "            yaxis_title=\"Value\",\n",
    "            template=\"plotly_white\",\n",
    "            height=550,\n",
    "        )\n",
    "        return fig\n",
    "\n",
    "    ds = get_dataset_dict(dataset_name if dataset_name != \"all\" else \"all\")\n",
    "    rec_samples = ds.get(action, {}).get(sensor, [])\n",
    "\n",
    "    def traces_for(df, prefix):\n",
    "        traces = []\n",
    "        for axis in [\"x\", \"y\", \"z\"]:\n",
    "            if axis in axes_on and axis in df.columns:\n",
    "                traces.append(go.Scatter(\n",
    "                    x=df[\"seconds_elapsed\"],\n",
    "                    y=df[axis],\n",
    "                    mode=\"lines\",\n",
    "                    name=f\"{prefix}{axis}\",\n",
    "                    hovertemplate=\"t=%{x:.3f}s<br>\"+f\"{axis}=%{{y:.3f}}<extra></extra>\"\n",
    "                ))\n",
    "        return traces\n",
    "\n",
    "    if mode == \"overlay\":\n",
    "        for idx in selected_samples:\n",
    "            if 0 <= idx < len(rec_samples):\n",
    "                df = rec_samples[idx]\n",
    "                fig.add_traces(traces_for(df, prefix=f\"#{idx} \"))\n",
    "        fig.update_layout(\n",
    "            title=f\"[{dataset_name}] {action} — {sensor} — overlay {len(selected_samples)} sample(s)\",\n",
    "            xaxis_title=\"Time (s)\",\n",
    "            yaxis_title=\"Value\",\n",
    "            template=\"plotly_white\",\n",
    "            height=650,\n",
    "            legend={\"orientation\": \"h\", \"yanchor\": \"bottom\", \"y\": 1.02, \"x\": 0.01},\n",
    "        )\n",
    "    else:\n",
    "        rows = len(selected_samples)\n",
    "        domains = []\n",
    "        gap = 0.04\n",
    "        panel = (1.0 - (rows - 1) * gap) / rows\n",
    "        for r in range(rows):\n",
    "            top = 1.0 - r * (panel + gap)\n",
    "            bottom = top - panel\n",
    "            domains.append((bottom, top))\n",
    "\n",
    "        for r, idx in enumerate(selected_samples):\n",
    "            if 0 <= idx < len(rec_samples):\n",
    "                df = rec_samples[idx]\n",
    "                yaxis_name = \"yaxis\" if r == 0 else f\"yaxis{r+1}\"\n",
    "                for tr in traces_for(df, prefix=f\"#{idx} \"):\n",
    "                    tr.update(yaxis=f\"y{'' if r == 0 else r+1}\")\n",
    "                    fig.add_trace(tr)\n",
    "                fig.update_layout(**{\n",
    "                    yaxis_name: dict(domain=list(domains[r]), title=f\"Sample #{idx}\"),\n",
    "                })\n",
    "\n",
    "        fig.update_layout(\n",
    "            title=f\"[{dataset_name}] {action} — {sensor} — {rows} separate panel(s)\",\n",
    "            xaxis=dict(title=\"Time (s)\"),\n",
    "            template=\"plotly_white\",\n",
    "            height=max(350, 280 * rows),\n",
    "            legend={\"orientation\": \"h\", \"yanchor\": \"bottom\", \"y\": 1.02, \"x\": 0.01},\n",
    "            margin=dict(t=60, r=30, l=60, b=40)\n",
    "        )\n",
    "\n",
    "    return fig\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # For Dash >= 2.0 use app.run, not app.run_server\n",
    "    host = os.environ.get(\"HOST\", \"127.0.0.1\")\n",
    "    port = int(os.environ.get(\"PORT\", \"8050\"))\n",
    "    app.run(host=host, port=port, debug=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
